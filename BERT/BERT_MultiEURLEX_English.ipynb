{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLB3I4FKZ5Lr"
   },
   "source": [
    "# Fine-tuning BERT for multi-label text classification English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wxY3x-ZZz8h",
    "outputId": "c7ef3a90-a6c7-477a-f951-b7a1244868b0"
   },
   "outputs": [],
   "source": [
    "# !pip install -q transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIH9NP0MZ6-O"
   },
   "source": [
    "## Load dataset\n",
    "\n",
    "Next, let's download a multi-label text classification dataset [MultiEURLEX](https://huggingface.co/datasets/multi_eurlex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "g5MNOwT4xKqH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "a1460512c5f1452e90bc943d2dbe1f1b",
      "16538a192cb7482aabbaae4b633802e5",
      "c5d1139ec488496bb5ed2add54bbbbc3",
      "b340d400a5a54da394eb030a89db63cd",
      "3fba3a22993c4aedb1cf3bf745291cf7",
      "a4d8b4662a5b4feba472c590f19a0f46",
      "5c4a113498a0434c905c86ff73b2abea",
      "1cd0041bd03f4028b421f7a44fc3c05e",
      "62471587c0c44a5182c4cb3033a78e19",
      "c986f7a7cc7547adbc76007edc044c2c",
      "4a372b0842fa4a3e9aaf869bc2250cfc"
     ]
    },
    "id": "sd1LiXGjZ420",
    "outputId": "ccfa6f9b-b217-48f7-d7b5-a764b77e31fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset multi_eurlex (/home/davo/.cache/huggingface/datasets/multi_eurlex/en/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00ee214ec5c4d7b82d5d790f67bb87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"multi_eurlex\", \"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCL02vQgxYTO"
   },
   "source": [
    "As we can see, the dataset contains 3 splits: one for training, one for validation and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qh1zti-xbYiq"
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset = dataset.rename_column(\"labels\", \"old_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBDCKGHmVq0T",
    "outputId": "8734b307-2eb5-44d4-d362-7394e742ec78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['celex_id', 'text', 'old_labels'],\n",
       "        num_rows: 55000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['celex_id', 'text', 'old_labels'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['celex_id', 'text', 'old_labels'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgS0wMWExcqP"
   },
   "source": [
    "Let's check the first example of the training split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unjuTtKUjZI3",
    "outputId": "dbba328e-10fb-438d-9e32-42856734ebfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'celex_id': '32006D0213',\n",
       " 'text': 'COMMISSION DECISION\\nof 6 March 2006\\nestablishing the classes of reaction-to-fire performance for certain construction products as regards wood flooring and solid wood panelling and cladding\\n(notified under document number C(2006) 655)\\n(Text with EEA relevance)\\n(2006/213/EC)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Directive 89/106/EEC of 21 December 1988, on the approximation of laws, regulations and administrative provisions of the Member States relating to construction products (1), and in particular Article 20(2) thereof,\\nWhereas:\\n(1)\\nDirective 89/106/EEC envisages that in order to take account of different levels of protection for construction works at national, regional or local level, it may be necessary to establish in the interpretative documents classes corresponding to the performance of products in respect of each essential requirement. Those documents have been published as the ‘Communication of the Commission with regard to the interpretative documents of Directive 89/106/EEC’ (2).\\n(2)\\nWith respect to the essential requirement of safety in the event of fire, interpretative document No 2 lists a number of interrelated measures which together define the fire safety strategy to be variously developed in the Member States.\\n(3)\\nInterpretative document No 2 identifies one of those measures as the limitation of the generation and spread of fire and smoke within a given area by limiting the potential of construction products to contribute to the full development of a fire.\\n(4)\\nThe level of that limitation may be expressed only in terms of the different levels of reaction-to-fire performance of the products in their end-use application;\\n(5)\\nBy way of harmonised solution, a system of classes was adopted in Commission Decision 2000/147/EC of 8 February 2000 implementing Council Directive 89/106/EEC as regards the classification of the reaction-to-fire performance of construction products (3).\\n(6)\\nIn the case of wood flooring and solid wood panelling and cladding it is necessary to use the classification established in Decision 2000/147/EC.\\n(7)\\nThe reaction-to-fire performance of many construction products and/or materials, within the classification provided for in Decision 2000/147/EC, is well established and sufficiently well known to fire regulators in Member States that they do not require testing for this particular performance characteristic.\\n(8)\\nThe measures provided for in this Decision are in accordance with the opinion of the Standing Committee on Construction,\\nHAS ADOPTED THIS DECISION:\\nArticle 1\\nThe construction products and/or materials which satisfy all the requirements of the performance characteristic ‘reaction to fire’ without need for further testing are set out in the Annex.\\nArticle 2\\nThe specific classes to be applied to different construction products and/or materials, within the reaction-to-fire classification adopted in Decision 2000/147/EC, are set out in the Annex to this Decision.\\nArticle 3\\nProducts shall be considered in relation to their end-use application, where relevant.\\nArticle 4\\nThis Decision is addressed to the Member States.\\nDone at Brussels, 6 March 2006.',\n",
       " 'old_labels': [1, 20, 7, 3, 0]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset['train'][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lables for EUROVOC concepts (21 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5vZhQpvkE8s",
    "outputId": "f7278c2b-a522-497f-a3bc-ffd7da9ec376"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['social questions',\n",
       " 'industry',\n",
       " 'finance',\n",
       " 'trade',\n",
       " 'business and competition',\n",
       " 'international relations',\n",
       " 'agriculture, forestry and fisheries',\n",
       " 'production, technology and research',\n",
       " 'transport',\n",
       " 'employment and working conditions',\n",
       " 'politics',\n",
       " 'law',\n",
       " 'education and communications',\n",
       " 'international organisations',\n",
       " 'energy',\n",
       " 'EUROPEAN UNION',\n",
       " 'science',\n",
       " 'agri-foodstuffs',\n",
       " 'geography',\n",
       " 'economics',\n",
       " 'environment']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['social questions',\n",
    " 'industry',\n",
    " 'finance',\n",
    " 'trade',\n",
    " 'business and competition',\n",
    " 'international relations',\n",
    " 'agriculture, forestry and fisheries',\n",
    " 'production, technology and research',\n",
    " 'transport',\n",
    " 'employment and working conditions',\n",
    " 'politics',\n",
    " 'law',\n",
    " 'education and communications',\n",
    " 'international organisations',\n",
    " 'energy',\n",
    " 'EUROPEAN UNION',\n",
    " 'science',\n",
    " 'agri-foodstuffs',\n",
    " 'geography',\n",
    " 'economics',\n",
    " 'environment']\n",
    "id2label = {0: 'social questions',\n",
    " 1: 'industry',\n",
    " 2: 'finance',\n",
    " 3: 'trade',\n",
    " 4: 'business and competition',\n",
    " 5: 'international relations',\n",
    " 6: 'agriculture, forestry and fisheries',\n",
    " 7: 'production, technology and research',\n",
    " 8: 'transport',\n",
    " 9: 'employment and working conditions',\n",
    " 10: 'politics',\n",
    " 11: 'law',\n",
    " 12: 'education and communications',\n",
    " 13: 'international organisations',\n",
    " 14: 'energy',\n",
    " 15: 'EUROPEAN UNION',\n",
    " 16: 'science',\n",
    " 17: 'agri-foodstuffs',\n",
    " 18: 'geography',\n",
    " 19: 'economics',\n",
    " 20: 'environment'}\n",
    "label2id = {'social questions': 0,\n",
    " 'industry': 1,\n",
    " 'finance': 2,\n",
    " 'trade': 3,\n",
    " 'business and competition': 4,\n",
    " 'international relations': 5,\n",
    " 'agriculture, forestry and fisheries': 6,\n",
    " 'production, technology and research': 7,\n",
    " 'transport': 8,\n",
    " 'employment and working conditions': 9,\n",
    " 'politics': 10,\n",
    " 'law': 11,\n",
    " 'education and communications': 12,\n",
    " 'international organisations': 13,\n",
    " 'energy': 14,\n",
    " 'EUROPEAN UNION': 15,\n",
    " 'science': 16,\n",
    " 'agri-foodstuffs': 17,\n",
    " 'geography': 18,\n",
    " 'economics': 19,\n",
    " 'environment': 20}\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJ3Teyjmank2"
   },
   "source": [
    "## Preprocess data\n",
    "\n",
    "As models like BERT don't expect text as direct input, but rather `input_ids`, etc., we tokenize the text using the tokenizer. Here I'm using the `AutoTokenizer` API, which will automatically load the appropriate tokenizer based on the checkpoint on the hub.\n",
    "\n",
    "What's a bit tricky is that we also need to provide labels to the model. For multi-label text classification, this is a matrix of shape (batch_size, num_labels). Also important: this should be a tensor of floats rather than integers, otherwise PyTorch' `BCEWithLogitsLoss` (which the model will use) will complain, as explained [here](https://discuss.pytorch.org/t/multi-label-binary-classification-result-type-float-cant-be-cast-to-the-desired-output-type-long/117915/3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TEQebh4p22NB"
   },
   "outputs": [],
   "source": [
    "def numbers_to_classes(l=[0,10,20]):\n",
    "  zero_cl = [0.0] * 21\n",
    "  for i in l:\n",
    "    zero_cl[i] = 1.0\n",
    "  \n",
    "  return np.array(zero_cl, dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPmxZtbb31EY",
    "outputId": "3aefa237-2631-4547-9e32-1b759ecaaf1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_to_classes(l=[0,10,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AFWlSsbZaRLc"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "  # take a batch of texts\n",
    "  text = examples[\"text\"]\n",
    "  # encode them\n",
    "  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=300)\n",
    "  # add labels\n",
    "\n",
    "  labels_matrix = []\n",
    "  for r in examples[\"old_labels\"]:\n",
    "    labels_matrix.append(np.array(numbers_to_classes(r), dtype=float))\n",
    "  # print(labels_matrix)\n",
    "  encoding[\"labels\"] = np.array(labels_matrix, dtype=float)\n",
    "  \n",
    "  return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "referenced_widgets": [
      "afccdd194fec4ede9c65846cb0781d68",
      "45746650248241e1942e8809c94b06a4",
      "8901c5d6493f42fcb90992f2db6e402b",
      "bca5bf694e1e44ce8be4e273f1c53ce2",
      "68abbd466ba64e8088b80c65bc0adb63",
      "c4f502d0988648d7996e1a55108a0fbe",
      "669f35f7f8fc4ad3b510972b19c69a3c",
      "d8f166d45b1c41d4b29e6cf63f5ed29d",
      "439053c658424b2f93a3f383b8d0af95",
      "3ab9eb89743744a9aa717dd82a129201",
      "73faac60485a45ef9234d3464b0b1c74",
      "b4a289a28e694652b8e8d6d518314f63",
      "d9d01b97af884a198cfea00559c1f199",
      "431cea2a52604dd4910542e1fac2d045",
      "66f61081b48d4f7785e1d150c3cb9a07",
      "91ae61f382f14883b9337f17dc8e7267",
      "c2582028d3ed41b9a32bc31df53a16dd",
      "df37c400a9014907a887fce2a5fc7042",
      "985db658d3614f1aabb57d173732f678",
      "ec1f581ed92148b5bee7ce0441f8d883",
      "686b34d4d82d4a5691fc6d4dfc51d0bb",
      "0571ec3060ae43b3811de5ccc85c9385",
      "4082b8176278445997a2453706b7b101",
      "d0b9d1bfa51546f8a775488417d3a684",
      "6c8eabd8b41f4cc4934c9c1f060026c6",
      "ca0cf0adf2bb4653b04cd85c25d14a3e",
      "1c66085d538641d28d132d723c053fa2",
      "adeb54cc7fa44b1f948595fb1e887926",
      "b3ff5b01b690434b8763f056165078c0",
      "9e9849e134bd42cba950405613d6cee6",
      "890e461de2bb4d2e902ca483b9c7b203",
      "fb31a2d5e23b465bb6abbdda03a17f02",
      "fe78160e25464f1589b6e09917c0f3f5"
     ]
    },
    "id": "i4ENBTdulBEI",
    "outputId": "a3266c2d-2dcc-4269-975d-9684cf05e941"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_data at 0x7f1de523e950> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8612054afe824bfba5e6193a60d15dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89608de7111f433da9650e5357dbf86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0165e678f84805b7bf7d726ec8b4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0enAb0W9o25W",
    "outputId": "840d2ddc-18f9-44a9-a2e9-fe2ea77d7d3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['celex_id', 'text', 'old_labels', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "example = encoded_dataset['train'][0]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "id": "D0McCtJ8HRJY",
    "outputId": "b9068821-7e2c-44db-c962-2e4a717b5534"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] commission decision of 6 march 2006 establishing the classes of reaction - to - fire performance for certain construction products as regards wood flooring and solid wood panelling and cladding ( notified under document number c ( 2006 ) 655 ) ( text with eea relevance ) ( 2006 / 213 / ec ) the commission of the european communities, having regard to the treaty establishing the european community, having regard to directive 89 / 106 / eec of 21 december 1988, on the approximation of laws, regulations and administrative provisions of the member states relating to construction products ( 1 ), and in particular article 20 ( 2 ) thereof, whereas : ( 1 ) directive 89 / 106 / eec envisages that in order to take account of different levels of protection for construction works at national, regional or local level, it may be necessary to establish in the interpretative documents classes corresponding to the performance of products in respect of each essential requirement. those documents have been published as the ‘ communication of the commission with regard to the interpretative documents of directive 89 / 106 / eec ’ ( 2 ). ( 2 ) with respect to the essential requirement of safety in the event of fire, interpretative document no 2 lists a number of interrelated measures which together define the fire safety strategy to be variously developed in the member states. ( 3 ) interpretative document no 2 identifies one of those measures as the limitation of the generation and spread of fire and smoke within a given area by limiting the potential of construction [SEP]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4Dx95t2o6N9",
    "outputId": "d70411e3-29fe-4e72-d156-e39367abe460"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['social questions',\n",
       " 'industry',\n",
       " 'trade',\n",
       " 'production, technology and research',\n",
       " 'environment']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgpKXDfvKBxn"
   },
   "source": [
    "Finally, we set the format of our data to PyTorch tensors. This will turn the training, validation and test sets into standard PyTorch [datasets](https://pytorch.org/docs/stable/data.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Lk6Cq9duKBkA"
   },
   "outputs": [],
   "source": [
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5qSmCgWefWs"
   },
   "source": [
    "## Define model\n",
    "\n",
    "Here we define a model that includes a pre-trained base (i.e. the weights from bert-base-uncased) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset.\n",
    "\n",
    "This is also printed by the warning.\n",
    "\n",
    "We set the `problem_type` to be \"multi_label_classification\", as this will make sure the appropriate loss function is used (namely [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)). We also make sure the output layer has `len(labels)` output neurons, and we set the id2label and label2id mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XPL1Z_RegBF",
    "outputId": "5e2f251f-82b9-4f0e-a90d-8054bd860044"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjJGEXShp7te"
   },
   "source": [
    "## Train the model!\n",
    "\n",
    "We are going to train the model using HuggingFace's Trainer API. This requires us to define 2 things: \n",
    "\n",
    "* `TrainingArguments`, which specify training hyperparameters. All options can be found in the [docs](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments). Below, we for example specify that we want to evaluate after every epoch of training, we would like to save the model every epoch, we set the learning rate, the batch size to use for training/evaluation, how many epochs to train for, and so on.\n",
    "* a `Trainer` object (docs can be found [here](https://huggingface.co/transformers/main_classes/trainer.html#id1))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "K5a8_vIKqr7P"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "metric_name = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dR2GmpvDqbuZ"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"bert-finetuned-sem_eval-english\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_v2fPFFJ3-v"
   },
   "source": [
    "We are also going to compute metrics while training. For this, we need to define a `compute_metrics` function, that returns a dictionary with the desired metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "797b2WHJqUgZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxNo4_TsvzDm"
   },
   "source": [
    "Let's verify a batch as well as a forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "IlOgGiojuWwG",
    "outputId": "b458483e-0d83-462c-fb34-39e5cc70c1f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train']['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V9wPaLZ7AXnV",
    "outputId": "9c79f006-3391-447d-e3d2-42456356486c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encoded_dataset['train']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  3222,  3247,  1997,  1020,  2233,  2294,  7411,  1996,  4280,\n",
       "         1997,  4668,  1011,  2000,  1011,  2543,  2836,  2005,  3056,  2810,\n",
       "         3688,  2004, 12362,  3536,  2723,  2075,  1998,  5024,  3536,  5997,\n",
       "         2989,  1998, 13681,  4667,  1006, 19488,  2104,  6254,  2193,  1039,\n",
       "         1006,  2294,  1007,  3515,  2629,  1007,  1006,  3793,  2007, 25212,\n",
       "         2050, 21923,  1007,  1006,  2294,  1013, 19883,  1013, 14925,  1007,\n",
       "         1996,  3222,  1997,  1996,  2647,  4279,  1010,  2383,  7634,  2000,\n",
       "         1996,  5036,  7411,  1996,  2647,  2451,  1010,  2383,  7634,  2000,\n",
       "        16449,  6486,  1013, 10114,  1013, 25212,  2278,  1997,  2538,  2285,\n",
       "         2997,  1010,  2006,  1996, 20167,  1997,  4277,  1010,  7040,  1998,\n",
       "         3831,  8910,  1997,  1996,  2266,  2163,  8800,  2000,  2810,  3688,\n",
       "         1006,  1015,  1007,  1010,  1998,  1999,  3327,  3720,  2322,  1006,\n",
       "         1016,  1007, 21739,  1010,  6168,  1024,  1006,  1015,  1007, 16449,\n",
       "         6486,  1013, 10114,  1013, 25212,  2278,  4372, 11365, 13923,  2008,\n",
       "         1999,  2344,  2000,  2202,  4070,  1997,  2367,  3798,  1997,  3860,\n",
       "         2005,  2810,  2573,  2012,  2120,  1010,  3164,  2030,  2334,  2504,\n",
       "         1010,  2009,  2089,  2022,  4072,  2000,  5323,  1999,  1996, 17841,\n",
       "         8082,  5491,  4280,  7978,  2000,  1996,  2836,  1997,  3688,  1999,\n",
       "         4847,  1997,  2169,  6827,  9095,  1012,  2216,  5491,  2031,  2042,\n",
       "         2405,  2004,  1996,  1520,  4807,  1997,  1996,  3222,  2007,  7634,\n",
       "         2000,  1996, 17841,  8082,  5491,  1997, 16449,  6486,  1013, 10114,\n",
       "         1013, 25212,  2278,  1521,  1006,  1016,  1007,  1012,  1006,  1016,\n",
       "         1007,  2007,  4847,  2000,  1996,  6827,  9095,  1997,  3808,  1999,\n",
       "         1996,  2724,  1997,  2543,  1010, 17841,  8082,  6254,  2053,  1016,\n",
       "         7201,  1037,  2193,  1997,  6970, 16570,  4383,  5761,  2029,  2362,\n",
       "         9375,  1996,  2543,  3808,  5656,  2000,  2022, 17611,  2764,  1999,\n",
       "         1996,  2266,  2163,  1012,  1006,  1017,  1007, 17841,  8082,  6254,\n",
       "         2053,  1016, 14847,  2028,  1997,  2216,  5761,  2004,  1996, 22718,\n",
       "         1997,  1996,  4245,  1998,  3659,  1997,  2543,  1998,  5610,  2306,\n",
       "         1037,  2445,  2181,  2011, 14879,  1996,  4022,  1997,  2810,   102])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train']['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxWcnZ8ku12V",
    "outputId": "909a444f-ae12-4402-fdc4-925f5bcdeb67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.6990, grad_fn=<BinaryCrossEntropyWithLogitsBackward>), logits=tensor([[ 0.7119, -0.4688,  0.4276,  0.1330,  0.2932,  0.0481, -0.4633, -0.3265,\n",
       "          0.0462, -0.1536, -0.1575,  0.1022, -0.5690, -0.4023,  0.2750,  0.1596,\n",
       "         -0.2457, -0.2454,  0.6577, -0.1985, -0.0819]],\n",
       "       grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass\n",
    "outputs = model(input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), labels=encoded_dataset['train']['labels'][0].unsqueeze(0))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-X2brZcv0X6"
   },
   "source": [
    "Let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "chq_3nUz73ib"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davo/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/davo/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/davo/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/davo/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "id": "KXmFds8js6P8",
    "outputId": "06ea76ea-8c6b-4ab1-abcc-26991cd26aab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, celex_id, old_labels. If text, celex_id, old_labels are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/davo/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 55000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34380\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdyada\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/davo/Desktop/wandb/run-20230331_113406-101doael</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dyada/huggingface/runs/101doael\" target=\"_blank\">bert-finetuned-sem_eval-english</a></strong> to <a href=\"https://wandb.ai/dyada/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34380' max='34380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34380/34380 3:43:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.143100</td>\n",
       "      <td>0.176575</td>\n",
       "      <td>0.805769</td>\n",
       "      <td>0.860744</td>\n",
       "      <td>0.278400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.165901</td>\n",
       "      <td>0.822025</td>\n",
       "      <td>0.878607</td>\n",
       "      <td>0.297200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.168147</td>\n",
       "      <td>0.822769</td>\n",
       "      <td>0.879608</td>\n",
       "      <td>0.280400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.171212</td>\n",
       "      <td>0.826784</td>\n",
       "      <td>0.884181</td>\n",
       "      <td>0.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.176813</td>\n",
       "      <td>0.827526</td>\n",
       "      <td>0.884803</td>\n",
       "      <td>0.313600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.181694</td>\n",
       "      <td>0.826149</td>\n",
       "      <td>0.886337</td>\n",
       "      <td>0.294000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.187533</td>\n",
       "      <td>0.824919</td>\n",
       "      <td>0.887558</td>\n",
       "      <td>0.305800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.194465</td>\n",
       "      <td>0.824165</td>\n",
       "      <td>0.887693</td>\n",
       "      <td>0.304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.197655</td>\n",
       "      <td>0.823381</td>\n",
       "      <td>0.885266</td>\n",
       "      <td>0.302400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.200037</td>\n",
       "      <td>0.824209</td>\n",
       "      <td>0.885911</td>\n",
       "      <td>0.307400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, celex_id, old_labels. If text, celex_id, old_labels are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-3438\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-3438/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-3438/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-3438/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-3438/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, celex_id, old_labels. If text, celex_id, old_labels are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-6876\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-6876/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-6876/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-6876/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-6876/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, celex_id, old_labels. If text, celex_id, old_labels are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-10314\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-10314/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-10314/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-10314/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-10314/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, celex_id, old_labels. If text, celex_id, old_labels are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-13752\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-13752/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-13752/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-13752/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-13752/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, celex_id, old_labels. If text, celex_id, old_labels are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-17190\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-17190/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-17190/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-17190/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-17190/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, celex_id, old_labels. If text, celex_id, old_labels are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-20628\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-20628/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-20628/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-20628/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-20628/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, celex_id, old_labels. If text, celex_id, old_labels are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-24066\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-24066/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-24066/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-24066/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-24066/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, celex_id, old_labels. If text, celex_id, old_labels are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-27504\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-27504/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-27504/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-27504/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-27504/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, celex_id, old_labels. If text, celex_id, old_labels are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-30942\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-30942/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-30942/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-30942/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-30942/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, celex_id, old_labels. If text, celex_id, old_labels are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english/checkpoint-34380\n",
      "Configuration saved in bert-finetuned-sem_eval-english/checkpoint-34380/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english/checkpoint-34380/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english/checkpoint-34380/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english/checkpoint-34380/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from bert-finetuned-sem_eval-english/checkpoint-17190 (score: 0.8275255890442031).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=34380, training_loss=0.08310864580586041, metrics={'train_runtime': 13399.127, 'train_samples_per_second': 41.047, 'train_steps_per_second': 2.566, 'total_flos': 8.480611359e+16, 'train_loss': 0.08310864580586041, 'epoch': 10.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiloh9eMK91o"
   },
   "source": [
    "## Evaluate\n",
    "\n",
    "After training, we evaluate our model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "cMlebJ83LRYG",
    "outputId": "b18102e7-2198-4beb-c874-d39636f740ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, celex_id, old_labels. If text, celex_id, old_labels are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='626' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 04:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.17681264877319336,\n",
       " 'eval_f1': 0.8275255890442031,\n",
       " 'eval_roc_auc': 0.8848033126767937,\n",
       " 'eval_accuracy': 0.3136,\n",
       " 'eval_runtime': 39.4796,\n",
       " 'eval_samples_per_second': 126.648,\n",
       " 'eval_steps_per_second': 7.928,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nmvJp0pLq-3"
   },
   "source": [
    "## Inference\n",
    "\n",
    "Let's test the model on a new sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COUNCIL REGULATION (EU) No 1390/2013\\nof 16 December 2013\\non the allocation of fishing opportunities under the Protocol agreed between the European Union and the Union of the Comoros setting out the fishing opportunities and financial contribution provided for in the Fisheries Partnership Agreement currently in force between the two parties\\nTHE COUNCIL OF THE EUROPEAN UNION,\\nHaving regard to the Treaty on the Functioning of the European Union, and in particular Article 43(3) thereof,\\nHaving regard to the proposal from the European Commission,\\nWhereas:\\n(1)\\nOn 5 October 2006, the Council approved the conclusion of the Partnership Agreement in the fisheries sector between the European Community and the Union of the Comoros (the ‘Partnership Agreement’) by adopting Regulation (EC) No 1563/2006 (1).\\n(2)\\nThe European Union negotiated with the Union of the Comoros a new Protocol to the Partnership Agreement granting vessels of the European Union fishing opportunities in Comoros waters.\\n(3)\\nOn 16 December 2013, the Council adopted Decision 2013/786/EU (2) on the signing and provisional application of the new Protocol.\\n(4)\\nThe fishing opportunities among the Member States should be allocated for the period of application of the new Protocol.\\n(5)\\nCouncil Regulation (EC) No 1006/2008 (3) provides that the Commission is to inform the Member States concerned if it appears that the fishing opportunities allocated to the European Union under the new Protocol are not fully exhausted. If no reply is received within a time limit to be set by the Council, this will be considered as confirmation that the vessels of the Member State concerned are not making full use of their fishing opportunities during the period in question. That time limit should be set.\\n(6)\\nTo ensure that vessels of the European Union can continue their fishing activities, the new Protocol provides for its application by the Parties on a provisional basis as from 1 January 2014. This Regulation should therefore apply from the provisional application of the new Protocol,\\nHAS ADOPTED THIS REGULATION:\\nArticle 1\\n1. The fishing opportunities established under the Protocol agreed between the European Union and the Union of the Comoros setting out the fishing opportunities and financial contribution provided for by the Fisheries Partnership Agreement between the two parties currently in force (the ‘Protocol’) shall be allocated among the Member States as follows:\\n(a)\\n42 tuna seiners:\\n-\\nSpain: 21 vessels\\n-\\nFrance: 21 vessels\\n(b)\\n20 surface longliners:\\n-\\nSpain: 8 vessels\\n-\\nFrance: 9 vessels\\n-\\nPortugal: 3 vessels\\n2. Regulation (EC) No 1006/2008 shall apply without prejudice to the Protocol or the Fisheries Partnership Agreement.\\n3. The time limit within which the Member States are to confirm that they are not fully exhausting the fishing opportunities granted to them under the Fisheries Partnership Agreement, as provided by Article 10(1) of Regulation (EC) No 1006/2008, shall be set at ten working days from the date on which the Commission informs them that their fishing opportunities have not been fully exhausted.\\nArticle 2\\nThis Regulation shall enter into force on the day following its publication in the Official Journal of the European Union.\\nIt shall apply from 1 January 2014.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.\\nDone at Brussels, 16 December 2013.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below you can observe a few examples with their predicted outputs for Bert model and what actually was true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(text, thres_prob=0.5):\n",
    "    encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "    encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
    "\n",
    "    outputs = trainer.model(**encoding)\n",
    "    logits = outputs.logits\n",
    "    # apply sigmoid + threshold\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(logits.squeeze().cpu())\n",
    "    predictions = np.zeros(probs.shape)\n",
    "    predictions[np.where(probs >= thres_prob)] = 1\n",
    "    # turn predicted id's into actual label names\n",
    "    predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
    "\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_labels(text=dataset['test']['text'][0][:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels>>> ['international relations', 'agriculture, forestry and fisheries', 'geography']\n"
     ]
    }
   ],
   "source": [
    "print('predicted_labels>>>', predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true labels>>> ['international relations', 'agriculture, forestry and fisheries', 'EUROPEAN UNION', 'geography']\n"
     ]
    }
   ],
   "source": [
    "print('true labels>>>', [id2label[idx] for idx, label in enumerate(numbers_to_classes(dataset['test']['old_labels'][0])) if label == 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the case above Bert model was able to pick up all true categories but missed 'EUROPEAN UNION'  category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_labels(text=dataset['test']['text'][100][:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels>>> ['trade', 'agri-foodstuffs', 'geography']\n"
     ]
    }
   ],
   "source": [
    "print('predicted_labels>>>', predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true labels>>> ['trade', 'agriculture, forestry and fisheries', 'production, technology and research', 'agri-foodstuffs', 'geography']\n"
     ]
    }
   ],
   "source": [
    "print('true labels>>>', [id2label[idx] for idx, label in enumerate(numbers_to_classes(dataset['test']['old_labels'][100])) if label == 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the case above Bert model was able to pick up all true categories but missed 'production, technology and research'  and agriculture, forestry and fisheries categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_labels(text=dataset['test']['text'][1000][:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels>>> ['international relations', 'EUROPEAN UNION', 'geography']\n"
     ]
    }
   ],
   "source": [
    "print('predicted_labels>>>', predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true labels>>> ['trade', 'international relations', 'EUROPEAN UNION', 'geography']\n"
     ]
    }
   ],
   "source": [
    "print('true labels>>>', [id2label[idx] for idx, label in enumerate(numbers_to_classes(dataset['test']['old_labels'][1000])) if label == 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the case above Bert model was able to pick up all true categories but also missed 'trade' category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_labels(text=dataset['test']['text'][1111][:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels>>> ['social questions', 'trade', 'agri-foodstuffs']\n"
     ]
    }
   ],
   "source": [
    "print('predicted_labels>>>', predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true labels>>> ['trade', 'agri-foodstuffs']\n"
     ]
    }
   ],
   "source": [
    "print('true labels>>>', [id2label[idx] for idx, label in enumerate(numbers_to_classes(dataset['test']['old_labels'][1111])) if label == 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we capture trade and agri-foodstuffs but mislabel social questions category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_labels(text=dataset['test']['text'][2230][:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels>>> ['trade', 'agri-foodstuffs']\n"
     ]
    }
   ],
   "source": [
    "print('predicted_labels>>>', predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true labels>>> ['trade', 'agri-foodstuffs']\n"
     ]
    }
   ],
   "source": [
    "print('true labels>>>', [id2label[idx] for idx, label in enumerate(numbers_to_classes(dataset['test']['old_labels'][2230])) if label == 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on output above we can observe that Bert returns also fully correct list of labels as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on examples above it is clear thta BERT model learned to pick up majority of the categories but very often missed one category from the true category list.  Good part Bert picks up majority of the classes, bad it often misses one class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics that would be useful for multilabel classification are F1 score and AUC/ROC curve. We will stick to F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.17681264877319336,\n",
       " 'eval_f1': 0.8275255890442031,\n",
       " 'eval_roc_auc': 0.8848033126767937,\n",
       " 'eval_accuracy': 0.3136,\n",
       " 'eval_runtime': 39.4796,\n",
       " 'eval_samples_per_second': 126.648,\n",
       " 'eval_steps_per_second': 7.928,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "{'eval_loss': 0.17681264877319336,\n",
    " 'eval_f1': 0.8275255890442031,\n",
    " 'eval_roc_auc': 0.8848033126767937,\n",
    " 'eval_accuracy': 0.3136,\n",
    " 'eval_runtime': 39.4796,\n",
    " 'eval_samples_per_second': 126.648,\n",
    " 'eval_steps_per_second': 7.928,\n",
    " 'epoch': 10.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0571ec3060ae43b3811de5ccc85c9385": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16538a192cb7482aabbaae4b633802e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4d8b4662a5b4feba472c590f19a0f46",
      "placeholder": "​",
      "style": "IPY_MODEL_5c4a113498a0434c905c86ff73b2abea",
      "value": "100%"
     }
    },
    "1c66085d538641d28d132d723c053fa2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "1cd0041bd03f4028b421f7a44fc3c05e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ab9eb89743744a9aa717dd82a129201": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fba3a22993c4aedb1cf3bf745291cf7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4082b8176278445997a2453706b7b101": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d0b9d1bfa51546f8a775488417d3a684",
       "IPY_MODEL_6c8eabd8b41f4cc4934c9c1f060026c6",
       "IPY_MODEL_ca0cf0adf2bb4653b04cd85c25d14a3e"
      ],
      "layout": "IPY_MODEL_1c66085d538641d28d132d723c053fa2"
     }
    },
    "431cea2a52604dd4910542e1fac2d045": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_985db658d3614f1aabb57d173732f678",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec1f581ed92148b5bee7ce0441f8d883",
      "value": 5000
     }
    },
    "439053c658424b2f93a3f383b8d0af95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "45746650248241e1942e8809c94b06a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4f502d0988648d7996e1a55108a0fbe",
      "placeholder": "​",
      "style": "IPY_MODEL_669f35f7f8fc4ad3b510972b19c69a3c",
      "value": "Map: 100%"
     }
    },
    "4a372b0842fa4a3e9aaf869bc2250cfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c4a113498a0434c905c86ff73b2abea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62471587c0c44a5182c4cb3033a78e19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "669f35f7f8fc4ad3b510972b19c69a3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66f61081b48d4f7785e1d150c3cb9a07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_686b34d4d82d4a5691fc6d4dfc51d0bb",
      "placeholder": "​",
      "style": "IPY_MODEL_0571ec3060ae43b3811de5ccc85c9385",
      "value": " 5000/5000 [00:33&lt;00:00, 151.38 examples/s]"
     }
    },
    "686b34d4d82d4a5691fc6d4dfc51d0bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68abbd466ba64e8088b80c65bc0adb63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "6c8eabd8b41f4cc4934c9c1f060026c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e9849e134bd42cba950405613d6cee6",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_890e461de2bb4d2e902ca483b9c7b203",
      "value": 1000
     }
    },
    "73faac60485a45ef9234d3464b0b1c74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8901c5d6493f42fcb90992f2db6e402b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8f166d45b1c41d4b29e6cf63f5ed29d",
      "max": 11000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_439053c658424b2f93a3f383b8d0af95",
      "value": 11000
     }
    },
    "890e461de2bb4d2e902ca483b9c7b203": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "91ae61f382f14883b9337f17dc8e7267": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "985db658d3614f1aabb57d173732f678": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e9849e134bd42cba950405613d6cee6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1460512c5f1452e90bc943d2dbe1f1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_16538a192cb7482aabbaae4b633802e5",
       "IPY_MODEL_c5d1139ec488496bb5ed2add54bbbbc3",
       "IPY_MODEL_b340d400a5a54da394eb030a89db63cd"
      ],
      "layout": "IPY_MODEL_3fba3a22993c4aedb1cf3bf745291cf7"
     }
    },
    "a4d8b4662a5b4feba472c590f19a0f46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adeb54cc7fa44b1f948595fb1e887926": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afccdd194fec4ede9c65846cb0781d68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45746650248241e1942e8809c94b06a4",
       "IPY_MODEL_8901c5d6493f42fcb90992f2db6e402b",
       "IPY_MODEL_bca5bf694e1e44ce8be4e273f1c53ce2"
      ],
      "layout": "IPY_MODEL_68abbd466ba64e8088b80c65bc0adb63"
     }
    },
    "b340d400a5a54da394eb030a89db63cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c986f7a7cc7547adbc76007edc044c2c",
      "placeholder": "​",
      "style": "IPY_MODEL_4a372b0842fa4a3e9aaf869bc2250cfc",
      "value": " 3/3 [00:00&lt;00:00, 91.72it/s]"
     }
    },
    "b3ff5b01b690434b8763f056165078c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4a289a28e694652b8e8d6d518314f63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d9d01b97af884a198cfea00559c1f199",
       "IPY_MODEL_431cea2a52604dd4910542e1fac2d045",
       "IPY_MODEL_66f61081b48d4f7785e1d150c3cb9a07"
      ],
      "layout": "IPY_MODEL_91ae61f382f14883b9337f17dc8e7267"
     }
    },
    "bca5bf694e1e44ce8be4e273f1c53ce2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ab9eb89743744a9aa717dd82a129201",
      "placeholder": "​",
      "style": "IPY_MODEL_73faac60485a45ef9234d3464b0b1c74",
      "value": " 11000/11000 [00:48&lt;00:00, 223.68 examples/s]"
     }
    },
    "c2582028d3ed41b9a32bc31df53a16dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4f502d0988648d7996e1a55108a0fbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5d1139ec488496bb5ed2add54bbbbc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1cd0041bd03f4028b421f7a44fc3c05e",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62471587c0c44a5182c4cb3033a78e19",
      "value": 3
     }
    },
    "c986f7a7cc7547adbc76007edc044c2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca0cf0adf2bb4653b04cd85c25d14a3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb31a2d5e23b465bb6abbdda03a17f02",
      "placeholder": "​",
      "style": "IPY_MODEL_fe78160e25464f1589b6e09917c0f3f5",
      "value": " 1000/1000 [00:05&lt;00:00, 172.50 examples/s]"
     }
    },
    "d0b9d1bfa51546f8a775488417d3a684": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_adeb54cc7fa44b1f948595fb1e887926",
      "placeholder": "​",
      "style": "IPY_MODEL_b3ff5b01b690434b8763f056165078c0",
      "value": "Map: 100%"
     }
    },
    "d8f166d45b1c41d4b29e6cf63f5ed29d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9d01b97af884a198cfea00559c1f199": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2582028d3ed41b9a32bc31df53a16dd",
      "placeholder": "​",
      "style": "IPY_MODEL_df37c400a9014907a887fce2a5fc7042",
      "value": "Map: 100%"
     }
    },
    "df37c400a9014907a887fce2a5fc7042": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec1f581ed92148b5bee7ce0441f8d883": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fb31a2d5e23b465bb6abbdda03a17f02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe78160e25464f1589b6e09917c0f3f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
