{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLB3I4FKZ5Lr"
   },
   "source": [
    "# Fine-tuning BERT French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wxY3x-ZZz8h",
    "outputId": "c7ef3a90-a6c7-477a-f951-b7a1244868b0"
   },
   "outputs": [],
   "source": [
    "# !pip install -q transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIH9NP0MZ6-O"
   },
   "source": [
    "## Load dataset\n",
    "\n",
    "Next, let's download a multi-label text classification dataset [MultiEURLEX](https://huggingface.co/datasets/multi_eurlex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "g5MNOwT4xKqH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "a1460512c5f1452e90bc943d2dbe1f1b",
      "16538a192cb7482aabbaae4b633802e5",
      "c5d1139ec488496bb5ed2add54bbbbc3",
      "b340d400a5a54da394eb030a89db63cd",
      "3fba3a22993c4aedb1cf3bf745291cf7",
      "a4d8b4662a5b4feba472c590f19a0f46",
      "5c4a113498a0434c905c86ff73b2abea",
      "1cd0041bd03f4028b421f7a44fc3c05e",
      "62471587c0c44a5182c4cb3033a78e19",
      "c986f7a7cc7547adbc76007edc044c2c",
      "4a372b0842fa4a3e9aaf869bc2250cfc"
     ]
    },
    "id": "sd1LiXGjZ420",
    "outputId": "ccfa6f9b-b217-48f7-d7b5-a764b77e31fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset multi_eurlex (/home/davo/.cache/huggingface/datasets/multi_eurlex/fr/1.0.0/8ec8b79877a517369a143ead6679d1788d13e51cf641ed29772f4449e8364fb6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe85eeecc084763aff5a5e15907118f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('multi_eurlex', 'fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCL02vQgxYTO"
   },
   "source": [
    "As we can see, the dataset contains 3 splits: one for training, one for validation and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qh1zti-xbYiq"
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset = dataset.rename_column(\"labels\", \"old_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBDCKGHmVq0T",
    "outputId": "8734b307-2eb5-44d4-d362-7394e742ec78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['celex_id', 'text', 'old_labels'],\n",
       "        num_rows: 55000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['celex_id', 'text', 'old_labels'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['celex_id', 'text', 'old_labels'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgS0wMWExcqP"
   },
   "source": [
    "Let's check the first example of the training split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unjuTtKUjZI3",
    "outputId": "dbba328e-10fb-438d-9e32-42856734ebfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'celex_id': '32006D0213',\n",
       " 'text': \"DÉCISION DE LA COMMISSION\\ndu 6 mars 2006\\nétablissant la classification des caractéristiques de réaction au feu de certains produits de construction pour ce qui concerne les sols en bois et les lambris et revêtements muraux extérieurs en bois massif\\n[notifiée sous le numéro C(2006) 655]\\n(Texte présentant de l'intérêt pour l'EEE)\\n(2006/213/CE)\\nLA COMMISSION DES COMMUNAUTÉS EUROPÉENNES,\\nVu le traité instituant la Communauté européenne,\\nVu la directive 89/106/CEE du Conseil du 21 décembre 1988 relative au rapprochement des dispositions législatives, réglementaires et administratives des États membres concernant les produits de construction (1), et notamment son article 20, paragraphe 2,\\nConsidérant ce qui suit:\\n(1)\\nLa directive 89/106/CEE considère que, afin de tenir compte des différences de niveau de protection existant à l’échelon national, régional ou local, il peut être nécessaire, pour chaque exigence essentielle, d’établir des classes de performance des produits dans les document interprétatifs. Ces documents ont été publiés sous forme d’une «communication de la Commission concernant les documents interprétatifs de la directive 89/106/CEE (2)».\\n(2)\\nEn ce qui concerne l’exigence essentielle relative à la sécurité en cas d’incendie, le document interprétatif no 2 dresse une liste de mesures interdépendantes qui, ensemble, définissent la stratégie en matière de sécurité en cas d’incendie qui peut être mise en œuvre de différentes manières dans les États membres.\\n(3)\\nUne des mesures identifiées dans le document interprétatif no 2 est la limitation de l’apparition et de la propagation du feu et de la fumée dans un espace donné en limitant la contribution possible des produits de construction au plein développement d’un incendie.\\n(4)\\nCette limitation ne peut être exprimée qu’en termes de différentes classes de caractéristiques de réaction au feu des produits dans les conditions de leur utilisation finale.\\n(5)\\nDans le cadre d’une solution harmonisée, la décision 2000/147/CE de la Commission du 8 février 2000 portant modalités d’application de la directive 89/106/CEE du Conseil en ce qui concerne la classification des caractéristiques de réaction au feu des produits de construction (3) a instauré un système de classes.\\n(6)\\nPour les sols en bois et les lambris et revêtements muraux extérieurs en bois massif, il est nécessaire d’utiliser la classification instaurée par la décision 2000/147/CE.\\n(7)\\nPour de nombreux produits et/ou matériaux de construction, les caractéristiques de réaction au feu telles que définies dans la classification de la décision 2000/147/CE sont bien établies et suffisamment connues des autorités des États membres en matière de sécurité incendie. Il n’est donc plus nécessaire de leur faire subir des essais supplémentaires à cet égard.\\n(8)\\nLes mesures prévues dans la présente décision sont conformes à l’avis du comité permanent de la construction,\\nA ARRÊTÉ LA PRÉSENTE DÉCISION:\\nArticle premier\\nLes produits et/ou matériaux de construction qui satisfont à l’ensemble des prescriptions relatives à la caractéristique «réaction au feu» sans devoir subir d’essais complémentaires sont énumérés à l’annexe.\\nArticle 2\\nLes classes spécifiques à appliquer aux différents produits et/ou matériaux de construction au sein de la classification des caractéristiques de réaction au feu adoptées par la décision 2000/147/CE sont indiquées à l’annexe de la présente décision.\\nArticle 3\\nLes produits sont considérés au regard des conditions de leur utilisation finale, le cas échéant.\\nArticle 4\\nLes États membres sont destinataires de la présente décision.\\nFait à Bruxelles, le 6 mars 2006.\",\n",
       " 'old_labels': [1, 20, 7, 3, 0]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset['train'][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DV0Rtetxgd4"
   },
   "source": [
    "The dataset consists of tweets, labeled with one or more emotions. \n",
    "\n",
    "Let's create a list that contains the labels, as well as 2 dictionaries that map labels to integers and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5vZhQpvkE8s",
    "outputId": "f7278c2b-a522-497f-a3bc-ffd7da9ec376"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['social questions',\n",
       " 'industry',\n",
       " 'finance',\n",
       " 'trade',\n",
       " 'business and competition',\n",
       " 'international relations',\n",
       " 'agriculture, forestry and fisheries',\n",
       " 'production, technology and research',\n",
       " 'transport',\n",
       " 'employment and working conditions',\n",
       " 'politics',\n",
       " 'law',\n",
       " 'education and communications',\n",
       " 'international organisations',\n",
       " 'energy',\n",
       " 'EUROPEAN UNION',\n",
       " 'science',\n",
       " 'agri-foodstuffs',\n",
       " 'geography',\n",
       " 'economics',\n",
       " 'environment']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['social questions',\n",
    " 'industry',\n",
    " 'finance',\n",
    " 'trade',\n",
    " 'business and competition',\n",
    " 'international relations',\n",
    " 'agriculture, forestry and fisheries',\n",
    " 'production, technology and research',\n",
    " 'transport',\n",
    " 'employment and working conditions',\n",
    " 'politics',\n",
    " 'law',\n",
    " 'education and communications',\n",
    " 'international organisations',\n",
    " 'energy',\n",
    " 'EUROPEAN UNION',\n",
    " 'science',\n",
    " 'agri-foodstuffs',\n",
    " 'geography',\n",
    " 'economics',\n",
    " 'environment']\n",
    "id2label = {0: 'social questions',\n",
    " 1: 'industry',\n",
    " 2: 'finance',\n",
    " 3: 'trade',\n",
    " 4: 'business and competition',\n",
    " 5: 'international relations',\n",
    " 6: 'agriculture, forestry and fisheries',\n",
    " 7: 'production, technology and research',\n",
    " 8: 'transport',\n",
    " 9: 'employment and working conditions',\n",
    " 10: 'politics',\n",
    " 11: 'law',\n",
    " 12: 'education and communications',\n",
    " 13: 'international organisations',\n",
    " 14: 'energy',\n",
    " 15: 'EUROPEAN UNION',\n",
    " 16: 'science',\n",
    " 17: 'agri-foodstuffs',\n",
    " 18: 'geography',\n",
    " 19: 'economics',\n",
    " 20: 'environment'}\n",
    "label2id = {'social questions': 0,\n",
    " 'industry': 1,\n",
    " 'finance': 2,\n",
    " 'trade': 3,\n",
    " 'business and competition': 4,\n",
    " 'international relations': 5,\n",
    " 'agriculture, forestry and fisheries': 6,\n",
    " 'production, technology and research': 7,\n",
    " 'transport': 8,\n",
    " 'employment and working conditions': 9,\n",
    " 'politics': 10,\n",
    " 'law': 11,\n",
    " 'education and communications': 12,\n",
    " 'international organisations': 13,\n",
    " 'energy': 14,\n",
    " 'EUROPEAN UNION': 15,\n",
    " 'science': 16,\n",
    " 'agri-foodstuffs': 17,\n",
    " 'geography': 18,\n",
    " 'economics': 19,\n",
    " 'environment': 20}\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJ3Teyjmank2"
   },
   "source": [
    "## Preprocess data\n",
    "\n",
    "As models like BERT don't expect text as direct input, but rather `input_ids`, etc., we tokenize the text using the tokenizer. Here I'm using the `AutoTokenizer` API, which will automatically load the appropriate tokenizer based on the checkpoint on the hub.\n",
    "\n",
    "What's a bit tricky is that we also need to provide labels to the model. For multi-label text classification, this is a matrix of shape (batch_size, num_labels). Also important: this should be a tensor of floats rather than integers, otherwise PyTorch' `BCEWithLogitsLoss` (which the model will use) will complain, as explained [here](https://discuss.pytorch.org/t/multi-label-binary-classification-result-type-float-cant-be-cast-to-the-desired-output-type-long/117915/3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TEQebh4p22NB"
   },
   "outputs": [],
   "source": [
    "def numbers_to_classes(l=[0,10,20]):\n",
    "  zero_cl = [0.0] * 21\n",
    "  for i in l:\n",
    "    zero_cl[i] = 1.0\n",
    "  \n",
    "  return np.array(zero_cl, dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPmxZtbb31EY",
    "outputId": "3aefa237-2631-4547-9e32-1b759ecaaf1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_to_classes(l=[0,10,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AFWlSsbZaRLc"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "  # take a batch of texts\n",
    "  text = examples[\"text\"]\n",
    "  # encode them\n",
    "  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=300)\n",
    "  # add labels\n",
    "  labels_matrix = []\n",
    "  for r in examples[\"old_labels\"]:\n",
    "    labels_matrix.append(np.array(numbers_to_classes(r), dtype=float))\n",
    "  # print(labels_matrix)\n",
    "  encoding[\"labels\"] = np.array(labels_matrix, dtype=float)\n",
    "  \n",
    "  return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "referenced_widgets": [
      "afccdd194fec4ede9c65846cb0781d68",
      "45746650248241e1942e8809c94b06a4",
      "8901c5d6493f42fcb90992f2db6e402b",
      "bca5bf694e1e44ce8be4e273f1c53ce2",
      "68abbd466ba64e8088b80c65bc0adb63",
      "c4f502d0988648d7996e1a55108a0fbe",
      "669f35f7f8fc4ad3b510972b19c69a3c",
      "d8f166d45b1c41d4b29e6cf63f5ed29d",
      "439053c658424b2f93a3f383b8d0af95",
      "3ab9eb89743744a9aa717dd82a129201",
      "73faac60485a45ef9234d3464b0b1c74",
      "b4a289a28e694652b8e8d6d518314f63",
      "d9d01b97af884a198cfea00559c1f199",
      "431cea2a52604dd4910542e1fac2d045",
      "66f61081b48d4f7785e1d150c3cb9a07",
      "91ae61f382f14883b9337f17dc8e7267",
      "c2582028d3ed41b9a32bc31df53a16dd",
      "df37c400a9014907a887fce2a5fc7042",
      "985db658d3614f1aabb57d173732f678",
      "ec1f581ed92148b5bee7ce0441f8d883",
      "686b34d4d82d4a5691fc6d4dfc51d0bb",
      "0571ec3060ae43b3811de5ccc85c9385",
      "4082b8176278445997a2453706b7b101",
      "d0b9d1bfa51546f8a775488417d3a684",
      "6c8eabd8b41f4cc4934c9c1f060026c6",
      "ca0cf0adf2bb4653b04cd85c25d14a3e",
      "1c66085d538641d28d132d723c053fa2",
      "adeb54cc7fa44b1f948595fb1e887926",
      "b3ff5b01b690434b8763f056165078c0",
      "9e9849e134bd42cba950405613d6cee6",
      "890e461de2bb4d2e902ca483b9c7b203",
      "fb31a2d5e23b465bb6abbdda03a17f02",
      "fe78160e25464f1589b6e09917c0f3f5"
     ]
    },
    "id": "i4ENBTdulBEI",
    "outputId": "a3266c2d-2dcc-4269-975d-9684cf05e941"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_data at 0x7fbfc1109200> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ce794c30f54426b7b72051182c1893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442efe904a79440b849099830fb2b25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4c479de93546e6bc88490c6808133d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0enAb0W9o25W",
    "outputId": "840d2ddc-18f9-44a9-a2e9-fe2ea77d7d3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['celex_id', 'text', 'old_labels', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "example = encoded_dataset['train'][0]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "id": "D0McCtJ8HRJY",
    "outputId": "b9068821-7e2c-44db-c962-2e4a717b5534"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] decision de la commission du 6 mars 2006 etablissant la classification des caracteristiques de reaction au feu de certains produits de construction pour ce qui concerne les sols en bois et les lambris et revetements muraux exterieurs en bois massif [ notifiee sous le numero c ( 2006 ) 655 ] ( texte presentant de l'interet pour l'eee ) ( 2006 / 213 / ce ) la commission des communautes europeennes, vu le traite instituant la communaute europeenne, vu la directive 89 / 106 / cee du conseil du 21 decembre 1988 relative au rapprochement des dispositions legislatives, reglementaires et administratives des etats membres concernant les produits de construction ( 1 ), et notamment son article 20, paragraphe 2, considerant ce qui suit : ( 1 ) la directive 89 / 106 / cee considere que, afin de tenir compte des differences de niveau de protection existant a l [UNK] echelon national, regional ou local, il peut etre necessaire, pour chaque exigence essentielle, d [UNK] etablir des classes de performance des produits dans les document interpretatifs. ces documents ont ete publies sous forme d [UNK] une « communication de la commission concernant les documents interpretatifs de la directive 89 / 106 / cee ( 2 ) ». ( 2 ) en ce qui concerne l [UNK] exigence essentielle relative a la securite en cas d [UNK] incendie, le document interpretatif no 2 dresse une liste de mesures interdependantes qui, ensemble, definissent la [SEP]\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4Dx95t2o6N9",
    "outputId": "d70411e3-29fe-4e72-d156-e39367abe460"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['social questions',\n",
       " 'industry',\n",
       " 'trade',\n",
       " 'production, technology and research',\n",
       " 'environment']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgpKXDfvKBxn"
   },
   "source": [
    "Finally, we set the format of our data to PyTorch tensors. This will turn the training, validation and test sets into standard PyTorch [datasets](https://pytorch.org/docs/stable/data.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Lk6Cq9duKBkA"
   },
   "outputs": [],
   "source": [
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5qSmCgWefWs"
   },
   "source": [
    "## Define model\n",
    "\n",
    "Here we define a model that includes a pre-trained base (i.e. the weights from bert-base-multilingual-uncased) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset.\n",
    "\n",
    "This is also printed by the warning.\n",
    "\n",
    "We set the `problem_type` to be \"multi_label_classification\", as this will make sure the appropriate loss function is used (namely [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)). We also make sure the output layer has `len(labels)` output neurons, and we set the id2label and label2id mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XPL1Z_RegBF",
    "outputId": "5e2f251f-82b9-4f0e-a90d-8054bd860044"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-multilingual-uncased\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjJGEXShp7te"
   },
   "source": [
    "## Train the model!\n",
    "\n",
    "We are going to train the model using HuggingFace's Trainer API. This requires us to define 2 things: \n",
    "\n",
    "* `TrainingArguments`, which specify training hyperparameters. All options can be found in the [docs](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments). Below, we for example specify that we want to evaluate after every epoch of training, we would like to save the model every epoch, we set the learning rate, the batch size to use for training/evaluation, how many epochs to train for, and so on.\n",
    "* a `Trainer` object (docs can be found [here](https://huggingface.co/transformers/main_classes/trainer.html#id1))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "K5a8_vIKqr7P"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "metric_name = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dR2GmpvDqbuZ"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"bert-finetuned-sem_eval-french\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_v2fPFFJ3-v"
   },
   "source": [
    "We are also going to compute metrics while training. For this, we need to define a `compute_metrics` function, that returns a dictionary with the desired metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "797b2WHJqUgZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxNo4_TsvzDm"
   },
   "source": [
    "Let's verify a batch as well as a forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "IlOgGiojuWwG",
    "outputId": "b458483e-0d83-462c-fb34-39e5cc70c1f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train']['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V9wPaLZ7AXnV",
    "outputId": "9c79f006-3391-447d-e3d2-42456356486c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encoded_dataset['train']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101, 15308, 10102, 10106, 13932, 10169,   127, 11362, 10231, 61684,\n",
       "        50975, 10106, 10485, 10143, 25731, 10102, 25274, 10257, 25506, 10102,\n",
       "        17492, 28575, 10102, 13154, 10343, 10630, 10379, 52089, 10152, 31680,\n",
       "        10109, 16556, 10137, 10152, 51231, 12531, 10137, 58831, 50345, 10107,\n",
       "        39721, 12204, 43311, 10107, 10109, 16556, 43835,   138, 69327, 66340,\n",
       "        11520, 10130, 11855,   145,   113, 10231,   114, 49168,   140,   113,\n",
       "        19703, 59627, 10102,   154,   112, 36719, 10343,   154,   112, 23329,\n",
       "        10111,   114,   113, 10231,   120, 21232,   120, 10630,   114, 10106,\n",
       "        13932, 10143, 66008, 65919,   117, 12310, 10130, 25269, 52119, 24422,\n",
       "        11539, 10106, 18816, 29417,   117, 12310, 10106, 92695, 12844,   120,\n",
       "        16141,   120, 10630, 10111, 10169, 16727, 10169, 10259, 14110, 10632,\n",
       "        23350, 10257, 20786, 50028, 70473, 10143, 53909, 10107, 55478,   117,\n",
       "        89590, 28666, 10137, 17376, 10107, 10143, 13371, 16294, 26903, 10152,\n",
       "        28575, 10102, 13154,   113,   122,   114,   117, 10137, 14311, 10289,\n",
       "        12877, 10200,   117, 10239, 52888, 10111,   123,   117, 74669, 10123,\n",
       "        10630, 10379, 23299,   131,   113,   122,   114, 10106, 92695, 12844,\n",
       "          120, 16141,   120, 10630, 10111, 25261, 10126,   117, 17307, 10102,\n",
       "        20390, 16659, 10143, 30980, 10102, 16182, 10102, 17297, 32628, 10368,\n",
       "          143,   154,   100, 76086, 18312, 10115, 10551,   117, 12536, 10391,\n",
       "        11467,   117, 10145, 12835, 11787, 48400,   117, 10343, 16711, 89405,\n",
       "        12897, 73878, 10301,   117,   146,   100, 64914, 10143, 18374, 10102,\n",
       "        13512, 10143, 28575, 10272, 10152, 22863, 38306, 70268,   119, 12139,\n",
       "        16469, 11593, 10951, 55651, 11520, 13529,   146,   100, 10249,   183,\n",
       "        19448, 10102, 10106, 13932, 26903, 10152, 16469, 38306, 70268, 10102,\n",
       "        10106, 92695, 12844,   120, 16141,   120, 10630, 10111,   113,   123,\n",
       "          114,   196,   119,   113,   123,   114, 10109, 10630, 10379, 52089,\n",
       "          154,   100, 89405, 12897, 73878, 10301, 23350,   143, 10106, 31164,\n",
       "        10109, 13945,   146,   100, 65691,   117, 10130, 22863, 38306, 21369,\n",
       "        10181,   123, 46836, 10111, 10249, 13593, 10102, 39808, 16355, 10282,\n",
       "        84244, 27477, 10379,   117, 14474,   117, 71772, 40536, 10106,   102])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train']['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxWcnZ8ku12V",
    "outputId": "909a444f-ae12-4402-fdc4-925f5bcdeb67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7026, grad_fn=<BinaryCrossEntropyWithLogitsBackward>), logits=tensor([[-0.0917,  0.0497,  0.0852,  0.0350, -0.1104, -0.0564,  0.0985,  0.1197,\n",
       "          0.0737,  0.1160,  0.0067,  0.0303,  0.0420,  0.1266, -0.0892, -0.0814,\n",
       "          0.1627,  0.0551,  0.0049,  0.1038,  0.0967]],\n",
       "       grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass\n",
    "outputs = model(input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), labels=encoded_dataset['train']['labels'][0].unsqueeze(0))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-X2brZcv0X6"
   },
   "source": [
    "Let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "chq_3nUz73ib"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davo/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/davo/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/davo/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/davo/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "id": "KXmFds8js6P8",
    "outputId": "06ea76ea-8c6b-4ab1-abcc-26991cd26aab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/davo/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 55000\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51570\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdyada\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/davo/Desktop/wandb/run-20230330_200416-3db7uyq8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dyada/huggingface/runs/3db7uyq8\" target=\"_blank\">bert-finetuned-sem_eval-french</a></strong> to <a href=\"https://wandb.ai/dyada/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51570' max='51570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51570/51570 5:43:33, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.180381</td>\n",
       "      <td>0.801885</td>\n",
       "      <td>0.863108</td>\n",
       "      <td>0.273200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.170703</td>\n",
       "      <td>0.816280</td>\n",
       "      <td>0.875694</td>\n",
       "      <td>0.287400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>0.171347</td>\n",
       "      <td>0.820302</td>\n",
       "      <td>0.878735</td>\n",
       "      <td>0.279600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>0.172468</td>\n",
       "      <td>0.819982</td>\n",
       "      <td>0.879797</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.176317</td>\n",
       "      <td>0.823362</td>\n",
       "      <td>0.881583</td>\n",
       "      <td>0.297400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>0.178507</td>\n",
       "      <td>0.822162</td>\n",
       "      <td>0.885190</td>\n",
       "      <td>0.284800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.184399</td>\n",
       "      <td>0.824527</td>\n",
       "      <td>0.885666</td>\n",
       "      <td>0.297400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.192329</td>\n",
       "      <td>0.827326</td>\n",
       "      <td>0.889268</td>\n",
       "      <td>0.303600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>0.200938</td>\n",
       "      <td>0.821519</td>\n",
       "      <td>0.884153</td>\n",
       "      <td>0.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.209489</td>\n",
       "      <td>0.822991</td>\n",
       "      <td>0.888141</td>\n",
       "      <td>0.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>0.212902</td>\n",
       "      <td>0.823081</td>\n",
       "      <td>0.887230</td>\n",
       "      <td>0.301600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.219738</td>\n",
       "      <td>0.822066</td>\n",
       "      <td>0.886917</td>\n",
       "      <td>0.298400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.224091</td>\n",
       "      <td>0.820817</td>\n",
       "      <td>0.884871</td>\n",
       "      <td>0.296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.225809</td>\n",
       "      <td>0.822261</td>\n",
       "      <td>0.885843</td>\n",
       "      <td>0.295400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.226956</td>\n",
       "      <td>0.822274</td>\n",
       "      <td>0.886665</td>\n",
       "      <td>0.297200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-3438\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-3438/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-3438/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-3438/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-3438/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-6876\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-6876/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-6876/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-6876/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-6876/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-10314\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-10314/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-10314/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-10314/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-10314/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-13752\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-13752/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-13752/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-13752/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-13752/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-17190\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-17190/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-17190/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-17190/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-17190/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-20628\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-20628/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-20628/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-20628/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-20628/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-24066\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-24066/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-24066/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-24066/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-24066/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-27504\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-27504/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-27504/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-27504/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-27504/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-30942\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-30942/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-30942/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-30942/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-30942/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-34380\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-34380/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-34380/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-34380/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-34380/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-37818\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-37818/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-37818/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-37818/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-37818/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-41256\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-41256/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-41256/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-41256/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-41256/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-44694\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-44694/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-44694/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-44694/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-44694/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-48132\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-48132/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-48132/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-48132/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-48132/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-french/checkpoint-51570\n",
      "Configuration saved in bert-finetuned-sem_eval-french/checkpoint-51570/config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-french/checkpoint-51570/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-french/checkpoint-51570/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-french/checkpoint-51570/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from bert-finetuned-sem_eval-french/checkpoint-27504 (score: 0.8273264896228522).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=51570, training_loss=0.07078056117234037, metrics={'train_runtime': 20620.909, 'train_samples_per_second': 40.008, 'train_steps_per_second': 2.501, 'total_flos': 1.27209170385e+17, 'train_loss': 0.07078056117234037, 'epoch': 15.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiloh9eMK91o"
   },
   "source": [
    "## Evaluate\n",
    "\n",
    "After training, we evaluate our model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "cMlebJ83LRYG",
    "outputId": "b18102e7-2198-4beb-c874-d39636f740ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: old_labels, celex_id, text. If old_labels, celex_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1923290342092514,\n",
       " 'eval_f1': 0.8273264896228522,\n",
       " 'eval_roc_auc': 0.8892684407566105,\n",
       " 'eval_accuracy': 0.3036,\n",
       " 'eval_runtime': 37.0849,\n",
       " 'eval_samples_per_second': 134.826,\n",
       " 'eval_steps_per_second': 8.44,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nmvJp0pLq-3"
   },
   "source": [
    "## Inference\n",
    "\n",
    "Let's test the model on a new sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RÈGLEMENT (UE) No 1390/2013 DU CONSEIL\\ndu 16 décembre 2013\\nrelatif à la répartition des possibilités de pêche au titre du protocole entre l'Union européenne et l'Union des Comores fixant les possibilités de pêche et la contrepartie financière prévues par l'accord de partenariat dans le secteur de la pêche en vigueur entre les deux parties\\nLE CONSEIL DE L'UNION EUROPÉENNE,\\nvu le traité sur le fonctionnement de l'Union européenne, et notamment son article 43, paragraphe 3,\\nvu la proposition de la Commission européenne,\\nconsidérant ce qui suit:\\n(1)\\nLe 5 octobre 2006, le Conseil a approuvé l'accord de partenariat dans le secteur de la pêche entre la Communauté européenne et l'Union des Comores (ci-après dénommé «accord de partenariat») en adoptant le règlement (CE) no 1563/2006 (1).\\n(2)\\nL'Union européenne a négocié avec l'Union des Comores un nouveau protocole à l'accord de partenariat accordant aux navires de l'Union européenne des possibilités de pêche dans les eaux comoriennes. À l'issue des négociations, un nouveau protocole a été paraphé le 5 juillet 2013.\\n(3)\\nLe 16 décembre 2013, le Conseil a adopté la décision 2013/786/UE (2) relative à la signature et à l'application provisoire du nouveau protocole.\\n(4)\\nIl convient de répartir des possibilités de pêche entre les États membres pour la période d'application du nouveau protocole.\\n(5)\\nConformément au règlement (CE) no 1006/2008 du Conseil (3), s'il apparaît que les possibilités de pêche allouées à l'Union européenne en vertu du nouveau protocole ne sont pas pleinement utilisées, la Commission en informe les États membres concernés. L'absence de réponse dans un délai à fixer par le Conseil est à considérer comme une confirmation que les navires de l'État membre concerné n'utilisent pas pleinement leurs possibilités de pêche pendant la période considérée. Il convient de fixer ledit délai.\\n(6)\\nAfin d'assurer la poursuite des activités de pêche des navires de l'Union européenne, le nouveau protocole prévoit la possibilité de son application à titre provisoire par chacune des parties à compter du 1er janvier 2014. Il convient donc que le présent règlement s'applique dès l'application provisoire du nouveau protocole,\\nA ADOPTÉ LE PRÉSENT RÈGLEMENT:\\nArticle premier\\n1. Les possibilités de pêche fixées par le protocole entre l'Union européenne et l'Union des Comores fixant les possibilités de pêche et la contrepartie financière prévues par l'accord de partenariat dans le secteur de la pêche en vigueur entre les deux parties (ci-après dénommé «protocole») sont réparties comme suit entre les États membres:\\na)\\n42 thoniers senneurs:\\n-\\nEspagne: 21 navires\\n-\\nFrance: 21 navires\\nb)\\n20 palangriers de surface:\\n-\\nEspagne: 8 navires\\n-\\nFrance: 9 navires\\n-\\nPortugal: 3 navires\\n2. Le règlement (CE) no 1006/2008 s'applique sans préjudice du protocole et de l'accord de partenariat.\\n3. Le délai dans lequel les États membres sont tenus de confirmer qu'ils n'utilisent pas pleinement les possibilités de pêche accordées au titre de l'accord de partenariat, tel que visé a l'article 10, paragraphe 1, du règlement (CE) no 1006/2008, est fixé à dix jours ouvrables à partir de la date à laquelle la Commission les informe que les possibilités de pêche ne sont pas pleinement utilisées.\\nArticle 2\\nLe présent règlement entre en vigueur le jour suivant celui de sa publication au Journal officiel de l'Union européenne.\\nIl est applicable à partir du 1er janvier 2014.\\nLe présent règlement est obligatoire dans tous ses éléments et directement applicable dans tout État membre.\\nFait à Bruxelles, le 16 décembre 2013.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below you can observe a few examples with their predicted outputs for Bert model and what actually was true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(text, thres_prob=0.5):\n",
    "    encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "    encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
    "\n",
    "    outputs = trainer.model(**encoding)\n",
    "    logits = outputs.logits\n",
    "    # apply sigmoid + threshold\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(logits.squeeze().cpu())\n",
    "    predictions = np.zeros(probs.shape)\n",
    "    predictions[np.where(probs >= thres_prob)] = 1\n",
    "    # turn predicted id's into actual label names\n",
    "    predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
    "\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_labels(text=dataset['test']['text'][0][:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels>>> ['international relations', 'agriculture, forestry and fisheries', 'EUROPEAN UNION', 'geography']\n"
     ]
    }
   ],
   "source": [
    "print('predicted_labels>>>', predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true labels>>> ['international relations', 'agriculture, forestry and fisheries', 'EUROPEAN UNION', 'geography']\n"
     ]
    }
   ],
   "source": [
    "print('true labels>>>', [id2label[idx] for idx, label in enumerate(numbers_to_classes(dataset['test']['old_labels'][0])) if label == 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the case above Bert model was able to pick up all true categories including 'EUROPEAN UNION'  category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_labels(text=dataset['test']['text'][100][:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels>>> ['trade', 'agriculture, forestry and fisheries', 'agri-foodstuffs', 'geography']\n"
     ]
    }
   ],
   "source": [
    "print('predicted_labels>>>', predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true labels>>> ['trade', 'agriculture, forestry and fisheries', 'production, technology and research', 'agri-foodstuffs', 'geography']\n"
     ]
    }
   ],
   "source": [
    "print('true labels>>>', [id2label[idx] for idx, label in enumerate(numbers_to_classes(dataset['test']['old_labels'][100])) if label == 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the case above Bert model was able to pick up all true categories but missed 'production, technology and research'  category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_labels(text=dataset['test']['text'][1000][:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels>>> ['international relations', 'EUROPEAN UNION', 'geography']\n"
     ]
    }
   ],
   "source": [
    "print('predicted_labels>>>', predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true labels>>> ['trade', 'international relations', 'EUROPEAN UNION', 'geography']\n"
     ]
    }
   ],
   "source": [
    "print('true labels>>>', [id2label[idx] for idx, label in enumerate(numbers_to_classes(dataset['test']['old_labels'][1000])) if label == 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the case above Bert model was able to pick up all true categories but also missed 'trade' category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_labels(text=dataset['test']['text'][1000][:512], thres_prob=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels>>> ['trade', 'international relations', 'transport', 'law', 'education and communications', 'EUROPEAN UNION', 'geography', 'economics']\n"
     ]
    }
   ],
   "source": [
    "print('predicted_labels>>>', predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true labels>>> ['trade', 'international relations', 'EUROPEAN UNION', 'geography']\n"
     ]
    }
   ],
   "source": [
    "print('true labels>>>', [id2label[idx] for idx, label in enumerate(numbers_to_classes(dataset['test']['old_labels'][1000])) if label == 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if we reduce threshold to 1% for accepting  a label as related to the class then we capture trade but mislabel transport, law, education and communications, economics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_labels(text=dataset['test']['text'][1111][:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels>>> ['social questions', 'production, technology and research', 'agri-foodstuffs']\n"
     ]
    }
   ],
   "source": [
    "print('predicted_labels>>>', predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true labels>>> ['trade', 'agri-foodstuffs']\n"
     ]
    }
   ],
   "source": [
    "print('true labels>>>', [id2label[idx] for idx, label in enumerate(numbers_to_classes(dataset['test']['old_labels'][1111])) if label == 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we don't capture trade  and mislabel social questions category and  'production, technology and research'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict_labels(text=dataset['test']['text'][2230][:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels>>> ['trade', 'agri-foodstuffs']\n"
     ]
    }
   ],
   "source": [
    "print('predicted_labels>>>', predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true labels>>> ['trade', 'agri-foodstuffs']\n"
     ]
    }
   ],
   "source": [
    "print('true labels>>>', [id2label[idx] for idx, label in enumerate(numbers_to_classes(dataset['test']['old_labels'][2230])) if label == 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on output above we can observe that Bert returns also fully correct list of labels as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on examples above it is clear thta BERT model learned to pick up majority of the categories but very often missed one category from the true category list.  Good part Bert picks up majority of the classes, bad it often misses one class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics that would be useful for multilabel classification are F1 score and AUC/ROC curve. We will stick to F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1923290342092514,\n",
       " 'eval_f1': 0.8273264896228522,\n",
       " 'eval_roc_auc': 0.8892684407566105,\n",
       " 'eval_accuracy': 0.3036,\n",
       " 'eval_runtime': 37.0849,\n",
       " 'eval_samples_per_second': 134.826,\n",
       " 'eval_steps_per_second': 8.44,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'eval_loss': 0.1923290342092514,\n",
    " 'eval_f1': 0.8273264896228522,\n",
    " 'eval_roc_auc': 0.8892684407566105,\n",
    " 'eval_accuracy': 0.3036,\n",
    " 'eval_runtime': 37.0849,\n",
    " 'eval_samples_per_second': 134.826,\n",
    " 'eval_steps_per_second': 8.44,\n",
    " 'epoch': 15.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## above we can observe performance measures of BERT model trained with 50 epochs for the test set with f1 score  82.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047619047619047616"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To compare with random classifier we have 21 categories so random classifier which always predicts same category should be able to obtain around 5% (equal distribution of categoris in datasets) accuracy while our model has 30.3% on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bert improvement of the model for French"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve Bert model for Frech language which has lower performance metrics compared to English and Spanish Bert models we will tokenizers specifically fine tuned on Fench language as previously we have used bert-base-multilingual-uncased. With using this approach it is highly likely we get higher performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0571ec3060ae43b3811de5ccc85c9385": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16538a192cb7482aabbaae4b633802e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4d8b4662a5b4feba472c590f19a0f46",
      "placeholder": "​",
      "style": "IPY_MODEL_5c4a113498a0434c905c86ff73b2abea",
      "value": "100%"
     }
    },
    "1c66085d538641d28d132d723c053fa2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "1cd0041bd03f4028b421f7a44fc3c05e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ab9eb89743744a9aa717dd82a129201": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fba3a22993c4aedb1cf3bf745291cf7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4082b8176278445997a2453706b7b101": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d0b9d1bfa51546f8a775488417d3a684",
       "IPY_MODEL_6c8eabd8b41f4cc4934c9c1f060026c6",
       "IPY_MODEL_ca0cf0adf2bb4653b04cd85c25d14a3e"
      ],
      "layout": "IPY_MODEL_1c66085d538641d28d132d723c053fa2"
     }
    },
    "431cea2a52604dd4910542e1fac2d045": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_985db658d3614f1aabb57d173732f678",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec1f581ed92148b5bee7ce0441f8d883",
      "value": 5000
     }
    },
    "439053c658424b2f93a3f383b8d0af95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "45746650248241e1942e8809c94b06a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4f502d0988648d7996e1a55108a0fbe",
      "placeholder": "​",
      "style": "IPY_MODEL_669f35f7f8fc4ad3b510972b19c69a3c",
      "value": "Map: 100%"
     }
    },
    "4a372b0842fa4a3e9aaf869bc2250cfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c4a113498a0434c905c86ff73b2abea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62471587c0c44a5182c4cb3033a78e19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "669f35f7f8fc4ad3b510972b19c69a3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66f61081b48d4f7785e1d150c3cb9a07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_686b34d4d82d4a5691fc6d4dfc51d0bb",
      "placeholder": "​",
      "style": "IPY_MODEL_0571ec3060ae43b3811de5ccc85c9385",
      "value": " 5000/5000 [00:33&lt;00:00, 151.38 examples/s]"
     }
    },
    "686b34d4d82d4a5691fc6d4dfc51d0bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68abbd466ba64e8088b80c65bc0adb63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "6c8eabd8b41f4cc4934c9c1f060026c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e9849e134bd42cba950405613d6cee6",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_890e461de2bb4d2e902ca483b9c7b203",
      "value": 1000
     }
    },
    "73faac60485a45ef9234d3464b0b1c74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8901c5d6493f42fcb90992f2db6e402b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8f166d45b1c41d4b29e6cf63f5ed29d",
      "max": 11000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_439053c658424b2f93a3f383b8d0af95",
      "value": 11000
     }
    },
    "890e461de2bb4d2e902ca483b9c7b203": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "91ae61f382f14883b9337f17dc8e7267": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "985db658d3614f1aabb57d173732f678": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e9849e134bd42cba950405613d6cee6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1460512c5f1452e90bc943d2dbe1f1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_16538a192cb7482aabbaae4b633802e5",
       "IPY_MODEL_c5d1139ec488496bb5ed2add54bbbbc3",
       "IPY_MODEL_b340d400a5a54da394eb030a89db63cd"
      ],
      "layout": "IPY_MODEL_3fba3a22993c4aedb1cf3bf745291cf7"
     }
    },
    "a4d8b4662a5b4feba472c590f19a0f46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adeb54cc7fa44b1f948595fb1e887926": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afccdd194fec4ede9c65846cb0781d68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45746650248241e1942e8809c94b06a4",
       "IPY_MODEL_8901c5d6493f42fcb90992f2db6e402b",
       "IPY_MODEL_bca5bf694e1e44ce8be4e273f1c53ce2"
      ],
      "layout": "IPY_MODEL_68abbd466ba64e8088b80c65bc0adb63"
     }
    },
    "b340d400a5a54da394eb030a89db63cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c986f7a7cc7547adbc76007edc044c2c",
      "placeholder": "​",
      "style": "IPY_MODEL_4a372b0842fa4a3e9aaf869bc2250cfc",
      "value": " 3/3 [00:00&lt;00:00, 91.72it/s]"
     }
    },
    "b3ff5b01b690434b8763f056165078c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4a289a28e694652b8e8d6d518314f63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d9d01b97af884a198cfea00559c1f199",
       "IPY_MODEL_431cea2a52604dd4910542e1fac2d045",
       "IPY_MODEL_66f61081b48d4f7785e1d150c3cb9a07"
      ],
      "layout": "IPY_MODEL_91ae61f382f14883b9337f17dc8e7267"
     }
    },
    "bca5bf694e1e44ce8be4e273f1c53ce2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ab9eb89743744a9aa717dd82a129201",
      "placeholder": "​",
      "style": "IPY_MODEL_73faac60485a45ef9234d3464b0b1c74",
      "value": " 11000/11000 [00:48&lt;00:00, 223.68 examples/s]"
     }
    },
    "c2582028d3ed41b9a32bc31df53a16dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4f502d0988648d7996e1a55108a0fbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5d1139ec488496bb5ed2add54bbbbc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1cd0041bd03f4028b421f7a44fc3c05e",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62471587c0c44a5182c4cb3033a78e19",
      "value": 3
     }
    },
    "c986f7a7cc7547adbc76007edc044c2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca0cf0adf2bb4653b04cd85c25d14a3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb31a2d5e23b465bb6abbdda03a17f02",
      "placeholder": "​",
      "style": "IPY_MODEL_fe78160e25464f1589b6e09917c0f3f5",
      "value": " 1000/1000 [00:05&lt;00:00, 172.50 examples/s]"
     }
    },
    "d0b9d1bfa51546f8a775488417d3a684": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_adeb54cc7fa44b1f948595fb1e887926",
      "placeholder": "​",
      "style": "IPY_MODEL_b3ff5b01b690434b8763f056165078c0",
      "value": "Map: 100%"
     }
    },
    "d8f166d45b1c41d4b29e6cf63f5ed29d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9d01b97af884a198cfea00559c1f199": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2582028d3ed41b9a32bc31df53a16dd",
      "placeholder": "​",
      "style": "IPY_MODEL_df37c400a9014907a887fce2a5fc7042",
      "value": "Map: 100%"
     }
    },
    "df37c400a9014907a887fce2a5fc7042": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec1f581ed92148b5bee7ce0441f8d883": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fb31a2d5e23b465bb6abbdda03a17f02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe78160e25464f1589b6e09917c0f3f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
